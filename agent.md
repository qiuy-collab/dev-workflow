# Agent Workflow Master Specification (Full Version)

## 0. Document Positioning

This file is the execution master specification for this repository, used to constrain all Agent behavior in this project.

Goals of this document:

- Ensure process consistency
- Ensure outputs are verifiable
- Ensure tests are traceable
- Ensure changes have closed loops
- Ensure reuse across users and tech stacks

Scope:

- All workflow executions in this repository
- All Skill invocations, tests, logs, and deliveries

---

## 1. General Execution Principles

### 1.1 Order Principle

The execution order is fixed as follows:

1. requirement-planning
2. api-design
3. backend-codegen
4. ui-ux-pro-max-local
5. frontend-dev
6. backend-scaffold
7. backend-core
8. final-delivery

Prohibited actions:

- Skipping steps
- Reversing order
- Executing subsequent Skills without dependencies satisfied

### 1.2 Dependency Principle

Before executing each Skill, prerequisite outputs must be verified.
If missing, you must:

1. Record an ERROR log
2. Terminate the current Skill
3. Return the missing items list

### 1.3 Documentation-First Principle

Any requirement change must update documents before code.
The required order is:

1. Update requirement documents
2. Update API documents
3. Modify implementation code
4. Re-run tests
5. Write back test reports
6. Write CHANGE logs

---

## 2. Mandatory Mechanisms (No Downgrade)

### FM-001 Automatic Acceptance Criteria Output

- Acceptance criteria in requirement-planning must be automatically generated by the Agent from the template.
- User input supplements business goals and does not replace acceptance criteria output.
- Acceptance criteria must be split by module and be testable.
- Acceptance criteria are auto-generated; do not ask the user for them.

### FM-002 autoMode Strong Constraints

Config items:

- `agent-config.json.workflow.autoMode`
- `agent-config.json.workflow.forceQuestioningOnFirstSkill`
- `agent-config.json.workflow.forceRequirementClarificationBeforeOutput`
- `true`: After requirements are completed, automatically execute to the final step.
- `false`: Must confirm before starting each Skill.
- `autoMode` only applies to major phase chaining (Skill-to-Skill), not mandatory sub-steps inside a Skill.
- When `forceQuestioningOnFirstSkill=true`, only the first Skill (requirement-planning) enforces mandatory questioning; subsequent Skills do not.
- When `forceRequirementClarificationBeforeOutput=true`, do not output the final requirement document until key information is clarified in requirement-planning.
- Do not forget this mode during execution.

### FM-003 Unified Test Gate at 100%

The following test gates must be 100%:

- frontend-dev
- backend-scaffold
- backend-core
- final-delivery

### FM-003A No Fake Tests / No Fabricated Reports (Mandatory)

- Test reports and summaries must be generated from **real executions** only.
- It is forbidden to write PASS/100% in reports or logs without actually:
  - starting the relevant service(s),
  - invoking real test commands (e.g., curl/playwright/pytest),
  - capturing real outputs.
- If a test cannot be executed, it must be recorded as FAIL or SKIP with reasons and impact.

### FM-004 Auto-Fix and Retest on Failure

If any test point fails, you must:

1. Identify the failure cause
2. Implement the fix
3. Re-run the same test point

### FM-005 Max 5 Retries Per Point

- A single test point may be retried at most 5 times
- If the limit is exceeded, SKIP is allowed
- SKIP must record scope of impact and follow-up suggestions

### FM-006 Required Test Log Fields

Each test point log must include:

- skill
- suite
- test_point
- test_status
- attempt/max_attempts
- message

Status enums:

- START
- PASS
- FAIL
- RETRY
- SKIP

### FM-007 Single-File Logging Mechanism

- Logging is required starting from Skill 1
- Unified output to: `logs/workflow.log`
- Do not split into execution/errors/changes multiple files
- If `logs/workflow.log` is missing, create it immediately and log an ERROR that logging was absent.
- If `logging.writeEnabled=false`, do not write logs (use only for dry runs).

### FM-008 Skill Source Resolution Mechanism

- Default global priority: `D:/niuma/newmax/resources/skills`
- Fallback to local only if global is missing: `./skills`
- Source decision must be written to workflow.log

### FM-009 Change Closure Enforcement

Any change to requirements, interfaces, models, or test strategy must update in sync:

- agent.md
- README.md
- QUICKSTART.md
- agent-config.json (if configuration involved)

### FM-010 Frontend Acceptance Traceability Matrix Enforcement

- The `frontend-dev` test report must map each `REQ-xxx` acceptance item one by one.
- Each acceptance item must include: test point ID, test method, result, evidence.
- Items without evidence must not be marked PASS.

### FM-011 Frontend E2E Interaction Acceptance Enforcement

- Interaction acceptance items must be covered by frontend E2E, not replaced by API-only cases.
- E2E test points must be automatically generated from `requirement-planning-requirements.md` acceptance items, not hard-coded in the general specification.
- E2E test points must label the source acceptance item (`REQ-xxx-y`) and corresponding page path.
- E2E failure handling follows the same 5-retry and log audit rules.

### FM-012 Mandatory UTF-8 File Writing

- All scripts writing files must explicitly specify UTF-8 encoding; do not rely on system defaults.
- PowerShell must use `-Encoding UTF8` or `[System.IO.File]::WriteAllText(..., [System.Text.UTF8Encoding]::new(...))`.
- Logs, reports, JSON, and Markdown must be written in UTF-8 to avoid garbled output and cross-environment encoding inconsistencies.

### FM-013 Output Contract Reading and In-Phase Validation Enforcement

- Before each Skill, read `agent-config.json -> skills.<skill>.validation.required` and `skills.<skill>.inputs`.
- Each Skill must first generate a “required outputs checklist,” then execute implementation steps.
- Before each Skill ends, perform a “file existence check.” If any required output is missing, log `ERROR` and enter the output remediation process; do not proceed to the next phase.
- `final-delivery` must re-verify the full existence of required outputs from the first 7 phases as a pre-delivery gate.

### FM-014 Evidence Requirement for Test Reports (Mandatory)

- Each PASS must reference concrete evidence (command, response snippet, screenshot, or log file line).
- Evidence must be captured from **the same run** as the test point.
- If evidence is missing, the test point cannot be marked PASS.

---

## 3. Directory Conventions

### 3.1 Directory Responsibilities

- `frontend/`: frontend code
- `backend/`: backend code
- `output/`: business documents and final delivery documents
- `test/`: test point lists and test reports
- `logs/`: workflow logs
- `runtime/`: runtime pid/temp files
- `scripts/`: scripts
- Executable Skill scripts go in `scripts/`; `skills/` only keeps `SKILL.md` and reference materials

### 3.2 Output Boundaries

`output/` only stores business documents and delivery documents; `test/` only stores test points and test reports; do not write source code into output/test.

### 3.3 Log Boundaries

Workflow logs are written only to `logs/workflow.log`.

---

## 4. Skill-Level Detailed Specifications

## 4.1 requirement-planning

### Input

- User business goals
- Functional scope
- Constraints (budget, time, platform)

### Required Steps

1. Clarify roles and scenarios
2. Split modules
3. Identify functional requirements
4. Identify non-functional requirements
5. Embed functional supplements (option-select) within questioning to expand features based on user choices
6. Mandatory questioning format: complete Q1-Q5, each with `options + custom answer`; do not merge into fewer question groups
7. Generate acceptance criteria by module (auto-generated, not asked)
8. Run UI visualization and confirmation (mandatory, see below)
9. Output priorities
10. Output tech stack

#### UI Visualization and Confirmation (Mandatory, Iterative)

After the 5 core questions are completed, you must execute three forced stages:

1. Generate a page list derived from confirmed requirements and user flow.
2. Produce an ASCII component visualization for each page (use the template in `skills/requirement-planning/references/ui-component-ascii-template.md`).
3. Force user confirmation in order:
  - Confirm component positions (iterate until confirmed).
  - Confirm UI style using candidates from `ui-ux-pro-max-local/data/*` (iterate until confirmed).
4. Generate requirement-stage UI drafts:
  - `output/ui/ui-spec.md`
  - `output/ui/ui-tokens.json`
  - `output/ui/ui-quality-metrics.md`

Only after all confirmations are explicit and draft files are generated may you proceed to the next phase or next Skill.

### Output

- `output/requirement-planning-requirements.md`
- `output/requirement-planning-tech-stack.json`
- `output/ui/ui-spec.md` (draft)
- `output/ui/ui-tokens.json` (draft)
- `output/ui/ui-quality-metrics.md` (draft)

### Validation

- Acceptance criteria are testable
- Acceptance criteria are organized by module
- Tech stack fields are complete

---

## 4.2 api-design

### Prerequisites

- requirement-planning outputs complete

### Required Steps

1. Model resources
2. Define routes
3. Define request parameters
4. Define response structures
5. Define error codes
6. Map requirement acceptance points

### Output

- `output/api-design-api-list.md`
- `output/api-design-data-models.md`
- `output/api-design-api-documentation.md` (optional)

### Validation

- Covers core flows
- Interfaces and data models are consistent
- Response structures are unified

---

## 4.3 backend-codegen

### Prerequisites

- requirement-planning + api-design

### Required Steps

1. Generate project structure
2. Generate config skeleton
3. Generate model skeleton
4. Generate routing skeleton
5. Generate database initialization plan

### Output

- `output/backend-codegen-project-structure.md`
- Backend source code written to `backend/`

### Validation

- Compiles
- Structure is complete
- Field naming aligned with api-design

---

## 4.4 ui-ux-pro-max-local

### Prerequisites

- requirement-planning + api-design + backend-codegen

### Required Steps

1. Read requirement + API outputs and requirement-stage UI drafts (including quality metrics)
2. Generate design-system baseline first (`design-system/MASTER.md` + `design-system/pages/*.md`)
3. Derive executable UI artifacts from design-system docs and overwrite draft UI outputs
4. Validate output completeness

### Output

- `design-system/MASTER.md`
- `design-system/pages/*.md`
- `output/ui/ui-spec.md`
- `output/ui/ui-tokens.json`
- `output/ui/ui-quality-metrics.md`

### Gate

- `design-system/MASTER.md`, `design-system/pages/*.md`, `output/ui/ui-spec.md`, `output/ui/ui-tokens.json`, `output/ui/ui-quality-metrics.md` must all exist before `frontend-dev`

---

## 4.5 frontend-dev

### Prerequisites

- requirement-planning + api-design + ui-ux-pro-max-local

### Required Steps

1. Build page structure
2. Integrate API client
3. Complete state management
4. Implement core interactions
5. Execute frontend tests
6. Write back frontend reports

### Output

- Frontend source code written to `frontend/`
- `output/ui/frontend-ui-implementation-notes.md`
- `test/frontend-dev/test-report.md`
- `test/frontend-dev/test-summary.json`
- `test/frontend-dev/e2e-test-report.md`
- `test/frontend-dev/e2e-test-summary.json`
- `test/frontend-dev/e2e-test-matrix.md`

### Test Gate

- Must be 100%
- `FE-E2E-*` test points belong to the `frontend-dev` suite and are written to the same test log stream

---

## 4.6 backend-scaffold

### Prerequisites

- requirement-planning + api-design + backend-codegen

### Required Steps

1. Start service
2. Initialize database
3. Run basic API smoke tests
4. Record failures and fix
5. Retest until gate passes

### Output

- `output/backend-scaffold/service-info.json`
- `test/backend-scaffold/api-test-report.md`
- `test/backend-scaffold/api-test-summary.json`

### Test Gate

- Must be 100%

---

## 4.7 backend-core

### Prerequisites

- requirement-planning + api-design + backend-codegen + backend-scaffold

### Required Steps

1. Complete core business interfaces
2. Implement pagination/filtering/sorting
3. Complete authn/authz
4. Complete error handling
5. Run comprehensive tests
6. Auto-fix and retest
7. Write back comprehensive report

### Output

- `output/backend-core/service-info.json`
- `test/backend-core/comprehensive-test-report.md`
- `test/backend-core/comprehensive-test-summary.json`

### Test Gate

- Must be 100%

---

## 4.8 final-delivery

### Prerequisites

- First three test reports pass the gate

### Required Steps

1. Verify frontend runs
2. Verify backend runs
3. Verify integration works
4. Check document completeness
5. Output delivery checklist

### Output

- `test/final-delivery/comprehensive-report.md`
- `output/final-delivery/delivery-summary.json`
- `output/final-delivery/delivery-manifest.md`
- Execution script: `scripts/final-delivery.ps1`

### Gate

- Must be 100%

---

## 5. Test System Definition

### 5.1 frontend-dev Test Points

- FE-BUILD-001: frontend build passes
- FE-UNIT-001: core unit tests pass
- FE-ROUTE-001: key pages accessible
- FE-API-001: API client call chain passes
- FE-STATE-001: key state transitions pass
- FE-UX-001: key interactions are non-blocking
- FE-TRACE-001: `REQ-xxx` acceptance items mapped one by one
- FE-TRACE-002: each PASS item has auditable evidence (logs/commands/screenshots/assertions)
- FE-E2E-*: interaction E2E test points automatically derived from `requirement-planning-requirements.md`

### 5.2 backend-scaffold Test Points

- BS-BOOT-001: service can start
- BS-DB-001: database initialization succeeds
- BS-AUTH-001: registration works
- BS-AUTH-002: login works
- BS-CRUD-001: create works
- BS-CRUD-002: read works
- BS-CRUD-003: delete works

### 5.3 backend-core Test Points

- BC-HEALTH-001: health check
- BC-AUTH-001: unauthorized blocked
- BC-AUTH-002: authorized access succeeds
- BC-CRUD-001: create
- BC-CRUD-002: detail
- BC-CRUD-003: update
- BC-CRUD-004: delete
- BC-PAGE-001: pagination
- BC-FILTER-001: filtering
- BC-SORT-001: sorting
- BC-CALENDAR-001: month view
- BC-CALENDAR-002: day view
- BC-MD-001: export
- BC-MD-002: import overwrite
- BC-ERR-001: 404 error handling

### 5.4 final-delivery Test Points

- FD-RUN-001: frontend running
- FD-RUN-002: backend running
- FD-INT-001: integration passes
- FD-UI-001: UI quality verified via configured mode (spacing on all pages, components >=4 types, interaction states, hierarchy/density thresholds) with evidence
- FD-DOC-001: docs complete
- FD-CONF-001: deployment config complete

### 5.5 Test Execution Consistency (Mandatory)

- Before testing, only clean test artifacts: `test/**/*test-report*.md`, `test/**/*summary*.json`, `test/test-points.jsonl`, and remove historical `phase=test` lines from `logs/workflow.log`; do not clean system logs or non-test files.
- Test mode must validate `testing.pointTransportMode=hybrid` and verify two sinks: `logs/workflow.log` and `test/test-points.jsonl`.
- Coverage verification must satisfy all three: each acceptance item in `requirement-planning-requirements.md` has test points, each `API-xxx` in `api-design-api-list.md` has cases, and comprehensive acceptance gates have been executed.
- Must produce four JSON summaries: `test/frontend-dev/test-summary.json`, `test/frontend-dev/e2e-test-summary.json`, `test/backend-scaffold/api-test-summary.json`, `test/backend-core/comprehensive-test-summary.json`.
- Any test point failure must follow “locate -> fix -> retest,” max 5 retries per point; after exceeding, only `SKIP` allowed, and root cause + impact must be recorded in logs and reports.
- Frontend interaction acceptance additionally requires `test/frontend-dev/e2e-test-matrix.md`, and must be referenced in the test report.

---

## 6. Auto-Fix and Retry Process

### 6.1 Standard Flow

1. `START`
2. Execute test
3. On failure, `FAIL`
4. Record root cause
5. Fix code
6. `RETRY`
7. On pass, `PASS`
8. If max attempts reached, `SKIP`

### 6.2 Minimum Root Cause Requirements

Must clearly state:

- Symptom
- Direct trigger condition
- Root cause
- Fix action
- Regression impact points

### 6.3 Retry Limit

- `maxAttempts = 5`
- Increment attempt count on each retry

---

## 7. Logging Specification

### 7.1 File

- `logs/workflow.log`
  - This file must exist before any test logging begins.

### 7.2 Levels

- INFO
- SUCCESS
- ERROR
- CHANGE

### 7.3 Lifecycle Logs

At least two per Skill:

- START
- END

### 7.4 Test Point Logs

Each test point must record:

- START
- PASS / FAIL
- RETRY (if any)
- SKIP (if any)

### 7.5 Recommended Format

`[timestamp] [level] skill=<skill> phase=<phase> suite=<suite> test_point=<point> test_status=<status> attempt=<n>/<max> message`

### 7.6 Example

`[2026-02-26 09:25:18] [SUCCESS] skill=backend-core phase=test suite=backend-core test_point=markdownImport test_status=PASS attempt=2/5 status=200,created=2,dayCount=2`

---

## 8. Configuration Specification

### 8.1 workflow

- `autoMode`

### 8.2 validation

- `maxRetries`
- `retryScope`
- `autoFixOnFailure`
- `testThreshold`

### 8.3 runtime

- `directory`
- `hotReload`

### 8.4 logging

- `writeEnabled = true` (set to `false` to disable log writing for dry runs)
- `singleFile = true`
- `fileName = workflow.log`
- `testPointLoggingRequired = true`

### 8.5 testing

- `pointTransportMode`: `realtime | json | hybrid`
- `pointTransportOptions.jsonRelayFile`
- `pointTransportOptions.fallbackToRealtimeOnJsonError`
- `frontendReportMode`: `requirement-traceability | smoke-summary`
- `frontendReportOptions.requireOneToOneMapping`
- `frontendReportOptions.requireEvidenceForPass`
- `frontendE2E.enabled`
- `frontendE2E.runner` (`playwright | cypress`)
- `frontendE2E.requireInteractionAcceptance`
- `uiQualityCheck.mode` (`script | devtools-mcp`) default `script`
- `uiQualityCheck.requireAllPages`

---

## 10. Requirement Change Retest Matrix

### 10.1 Requirement Text Change

- Must retest: requirement-planning related output consistency

### 10.2 API Field Change

- Must retest: api-design + frontend-dev + backend-scaffold + backend-core

### 10.3 Auth Change

- Must retest: backend-scaffold + backend-core + frontend login flow

### 10.4 Data Model Change

- Must retest: backend-codegen + backend-core + related frontend pages

### 10.5 Import/Export Change

- Must retest: backend-core markdown import/export + frontend import/export entry

---

## 11. Delivery Checklist

### 11.1 Required Documents

- requirement documents
- API design documents
- frontend test report
- backend smoke report
- backend comprehensive report

### 11.2 Required Runtime Info

- service address
- ports
- startup commands
- key dependency versions

### 11.3 Required Configuration

- `.env.example`
- startup script instructions

---

## 12. Prohibited Items

- No implementation changes without updating requirement documents
- Do not skip failed test points
- Do not falsify pass rate
- Do not split workflow logs into multiple files
- Do not use local Skills without recording source

---

## 13. Self-Check List (Before Execution)

- Confirmed autoMode read
- Confirmed forceQuestioningOnFirstSkill read
- Confirmed forceRequirementClarificationBeforeOutput read
- Confirmed Skill source strategy
- Confirmed test gate 100%
- Confirmed maxRetries=5
- Confirmed output path
- Confirmed required outputs contract for current Skill

## 14. Self-Check List (After Execution)

- Each Skill has START/END
- Each failed test point has FAIL + RETRY/PASS/SKIP
- Final pass rate statistics exist
- Test reports written back
- Change closure recorded
- Required outputs existence check completed
- No PASS without real execution evidence

---

## 15. Baseline Configuration Snippet

```json
{
  "workflow": {
    "autoMode": true,
    "forceQuestioningOnFirstSkill": true,
    "forceRequirementClarificationBeforeOutput": true
  },
  "validation": {
    "maxRetries": 5,
    "retryScope": "per-test-point",
    "autoFixOnFailure": true,
    "testThreshold": {
      "frontend": 1.0,
      "backend": 1.0
    }
  },
  "testing": {
    "pointTransportMode": "hybrid",
    "pointTransportOptions": {
      "jsonRelayFile": "test/test-points.jsonl",
      "fallbackToRealtimeOnJsonError": true
    },
    "frontendReportMode": "requirement-traceability",
    "frontendReportOptions": {
      "requireOneToOneMapping": true,
      "requireEvidenceForPass": true
    },
    "uiQualityCheck": {
      "mode": "script",
      "requireAllPages": true
    }
  },
  "runtime": {
    "directory": "./runtime"
  },
  "logging": {
    "writeEnabled": true,
    "singleFile": true,
    "fileName": "workflow.log",
    "testPointLoggingRequired": true
  }
}
```

---

## 16. Version History


| Version | Date       | Notes                                                                                                     |
| ------- | ---------- | --------------------------------------------------------------------------------------------------------- |
| 1.9.0   | 2026-02-27 | Ban fabricated test reports; require real execution evidence; ensure workflow.log exists                  |
| 1.10.0  | 2026-02-28 | ui-ux-pro-max-local changed to mandatory two-step outputs: design-system first, then ui-spec/ui-tokens    |
| 1.11.0  | 2026-02-28 | requirement-planning now must output UI draft files before ui-ux-pro-max-local refinement                 |
| 1.12.0  | 2026-02-28 | add UI quality metrics contract and frontend UI implementation notes for stronger visual consistency gate |
| 1.13.0  | 2026-03-01 | requirement-planning UI style question must source candidates from ui-ux-pro-max-local data files         |
| 1.8.0   | 2026-02-26 | Add mandatory frontend E2E interaction acceptance rules and E2E matrix output requirement                 |
| 1.7.0   | 2026-02-26 | Add test point transport mode config and frontend acceptance traceability matrix enforcement              |
| 1.6.0   | 2026-02-26 | Restore full mandatory mechanism spec, fill in audit items and execution details                          |
| 1.5.0   | 2026-02-26 | Adjust runtime and documentation specs                                                                    |
| 1.4.0   | 2026-02-26 | Change Skill source to global-first, local fallback                                                       |
| 1.3.0   | 2026-02-26 | Test gates at 100%, max 5 retries per failure                                                             |
| 1.0.0   | 2026-02-25 | Initial version                                                                                           |


&nbsp;
